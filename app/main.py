# from fastapi import FastAPI, HTTPException
# from pydantic import BaseModel
# from openai import OpenAI
# import os

# # ‚úÖ Cliente de OpenAI usando variable de entorno autom√°ticamente
# client = OpenAI()

# # ‚úÖ App de FastAPI
# app = FastAPI()

# # ‚úÖ Modelo de entrada
# class Prompt(BaseModel):
#     prompt: str

# # ‚úÖ Ruta POST
# @app.post("/generate")
# def generate(data: Prompt):
#     print(f"üì• Recibido prompt: {data.prompt}")
#     try:
#         response = client.chat.completions.create(
#             model="gpt-3.5-turbo",
#             messages=[{"role": "user", "content": data.prompt}],
#             max_tokens=150
#         )
#         return {"response": response.choices[0].message.content}
#     except Exception as e:
#         print(f"‚ùå Error OpenAI: {e}")
#         raise HTTPException(status_code=400, detail=str(e))





from fastapi import FastAPI, HTTPException, Request
from pydantic import BaseModel
from openai import OpenAI
import pandas as pd
import dateparser
import re
from datetime import datetime
import uuid

app = FastAPI()
client = OpenAI()

# ‚úÖ Memoria temporal en memoria
chat_history = {}

# ‚úÖ Base de datos simulada
data = [
    {"actividad": "T√≠teres en el parque", "edad_min": 3, "edad_max": 7, "ciudad": "madrid", "fecha": "2025-05-06", "interior": False},
    {"actividad": "Museo de Ciencia", "edad_min": 5, "edad_max": 12, "ciudad": "madrid", "fecha": "2025-05-06", "interior": True},
    {"actividad": "Cuentacuentos", "edad_min": 4, "edad_max": 10, "ciudad": "madrid", "fecha": "2025-05-07", "interior": True},
    {"actividad": "Parque aventuras", "edad_min": 6, "edad_max": 13, "ciudad": "madrid", "fecha": "2025-05-06", "interior": False},
    {"actividad": "Taller arte infantil", "edad_min": 5, "edad_max": 9, "ciudad": "madrid", "fecha": "2025-05-08", "interior": True},
]
df = pd.DataFrame(data)

class Prompt(BaseModel):
    prompt: str
    session_id: str = None  # opcional; se genera si no se pasa

# ‚úÖ Utilidades para extraer edad, ciudad y fecha

def extraer_edad(texto):
    match = re.search(r"(\d{1,2})\s*(a√±os|a√±o)", texto)
    if match:
        edad = int(match.group(1))
        if edad < 14:
            return edad
    return None

def extraer_ciudad(texto):
    ciudades = ["madrid"]
    for ciudad in ciudades:
        if ciudad.lower() in texto.lower():
            return ciudad.lower()
    return None

def extraer_fecha(texto):
    fecha = dateparser.parse(texto, settings={"PREFER_DATES_FROM": "future"})
    if fecha:
        return fecha.date().isoformat()
    return None

def obtener_clima(fecha, ciudad):
    return "nublado" if datetime.fromisoformat(fecha).day % 2 == 0 else "soleado"

# ‚úÖ Ruta principal con historial

@app.post("/generate")
def generate(data: Prompt):
    prompt = data.prompt.lower()
    session_id = data.session_id or str(uuid.uuid4())

    edad = extraer_edad(prompt)
    ciudad = extraer_ciudad(prompt)
    fecha = extraer_fecha(prompt)

    actividades = pd.DataFrame()
    clima = None

    if ciudad and edad and (fecha is not None):
        actividades = df[
            (df["edad_min"] <= edad) &
            (df["edad_max"] >= edad) &
            (df["ciudad"] == ciudad) &
            (df["fecha"] == fecha)
        ]
        clima = obtener_clima(fecha, ciudad)

    # ‚úÖ Generar mensaje propio si tenemos datos
    if not actividades.empty:
        preferidas = actividades[actividades["interior"] == (clima == "nublado")]
        if preferidas.empty:
            preferidas = actividades

        lista_actividades = "\n".join(f"- {a}" for a in preferidas["actividad"].tolist())
        respuesta = (
            f"¬°Hola! üòä Para el {fecha} en {ciudad.title()} con tu peque de {edad} a√±os, "
            f"te recomiendo estas actividades:\n{lista_actividades}.\n"
            f"El d√≠a estar√° {clima}, as√≠ que ¬°estas opciones son geniales!"
        )

        # ‚úÖ Guardar en historial
        chat_history.setdefault(session_id, [])
        chat_history[session_id].append({"role": "user", "content": data.prompt})
        chat_history[session_id].append({"role": "assistant", "content": respuesta})

        return {"response": respuesta, "session_id": session_id}

    # ‚úÖ Usar historial para completar con OpenAI
    chat_history.setdefault(session_id, [])
    chat_history[session_id].append({"role": "user", "content": data.prompt})

    history_limit = chat_history[session_id][-10:]  # √∫ltimas 5 interacciones
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": (
                    "Eres un asistente amable, familiar y √∫til para padres con ni√±os menores de 14 a√±os. "
                    "Solo das informaci√≥n relevante para actividades infantiles. No opinas sobre temas ajenos a ese objetivo."
                )},
                *history_limit
            ],
            max_tokens=150
        )
        respuesta_ai = response.choices[0].message.content
        chat_history[session_id].append({"role": "assistant", "content": respuesta_ai})

        return {"response": respuesta_ai, "session_id": session_id}
    except Exception as e:
        print(f"‚ùå Error OpenAI: {e}")
        raise HTTPException(status_code=400, detail=str(e))
